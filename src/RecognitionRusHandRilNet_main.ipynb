{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Recognition RusHandRilNet.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPyMDmWu8EQ02POveUZbNaj"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bi0-p9rdTnFw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.learn_data_struct import DataSet\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "38xMuAIHUcWD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class R2HandRilNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2HandRilNet, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=1,out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act3 = torch.nn.Tanh()\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act4 = torch.nn.ReLU()\n",
    "        self.conv4 = torch.nn.Conv2d(\n",
    "            in_channels=1,out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act5 = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act6 = torch.nn.Tanh()\n",
    "\n",
    "        self.conv5 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act7 = torch.nn.ReLU()\n",
    "        self.conv6 = torch.nn.Conv2d(\n",
    "            in_channels=1,out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act8 = torch.nn.ReLU()\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act9 = torch.nn.Tanh()\n",
    "\n",
    "        self.conv7 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act10 = torch.nn.ReLU()\n",
    "        self.conv8 = torch.nn.Conv2d(\n",
    "            in_channels=1,out_channels=2, kernel_size=3, stride=1, padding=1)\n",
    "        self.act11 = torch.nn.ReLU()\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act12 = torch.nn.Tanh()\n",
    "\n",
    "        self.conv9 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act13 = torch.nn.ReLU()\n",
    "        self.conv10 = torch.nn.Conv2d(\n",
    "            in_channels=1,out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.act14 = torch.nn.ReLU()\n",
    "        self.pool5 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.act14 = torch.nn.Tanh()\n",
    "\n",
    "        self.conv11 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=8, kernel_size=1, stride=1, padding=0)\n",
    "        self.act15 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(8, 63)\n",
    "        self.act16 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(63, 63)\n",
    "        self.act17 = torch.nn.Softmax()\n",
    "  \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.act6(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.act7(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.act8(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.act9(x)\n",
    "\n",
    "        x = self.conv7(x)\n",
    "        x = self.act10(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.act11(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.act12(x)\n",
    "\n",
    "        x = self.conv9(x)\n",
    "        x = self.act13(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.act13(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.act14(x)\n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.act15(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act16(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.act17(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "handrilnet = R2HandRilNet() "
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E3YJ6MGEAY4G",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "handrilnet = handrilnet.to(device)"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6cqqZYb1A9zW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "loss = torch.nn.CrossEntropyLoss()   #variable parameter\n",
    "optimizer = torch.optim.Adam(handrilnet.parameters(), lr=1.0e-3)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AFvpODCTBnwL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_dataset = DataSet(62)\n",
    "test_dataset = DataSet(1)\n",
    "x_train = train_dataset.batch().data\n",
    "y_train = train_dataset.batch().letter\n",
    "x_test = test_dataset.batch().data\n",
    "y_test = test_dataset.batch().letter"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../cut_img/5'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-4c0be7c552df>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtrain_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataSet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m62\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mtest_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataSet\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mx_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0my_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mletter\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mx_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/datataset_rhwl/src/learn_data_struct.py\u001B[0m in \u001B[0;36mbatch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[0msub_folder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msub_folder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m         \u001B[0mlist_image\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mletter_batch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__add_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist_image\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../cut_img/5'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bwh8pUnXMMFB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#x_train = x_train.unsqueeze(1).float()\n",
    "#x_test = x_test.unsqueeze(1).float()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u260fxCFTsvs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#x_train.shape()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hDF62bWfKqpy",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "batch_size = 10\n",
    "\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(5000):\n",
    "    order = np.random.permutation(len(x_train))\n",
    "    for start_index in range(0, len(x_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "\n",
    "        x_batch = x_train[batch_indexes].to(device)\n",
    "        y_batch = y_train[batch_indexes].to(device)\n",
    "\n",
    "        preds = handrilnet.forward(x_batch)\n",
    "\n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    test_preds = handrilnet.forward(x_test)\n",
    "    test_loss_history.append(loss(test_preds, y_test).to(device))\n",
    "\n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean().to(device)\n",
    "    test_accuracy_history.append(accuracy)\n",
    "\n",
    "    print(accuracy)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-8dc78c0fba18>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtest_loss_history\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mx_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0my_test\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'x_test' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zQwreWgbTAw7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "handrilnet.forward(x_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tGE4m-wsTOdF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "plt.plot(test_accuracy_history)\n",
    "# plt.plot(test_loss_history)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}